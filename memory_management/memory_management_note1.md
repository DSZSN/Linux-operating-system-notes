#### Linux 内存管理


## 内存管理难学原因:
* 网上二手资料存在很多错误地方.
* 目前购买的微机原理对内存的讲解,一上来就将数据结构、算法。对于没有对内存管理有清晰的宏观认识,很容易被讲晕。
* 内存管理带有很强的欺骗性。
 `比如当你申请一块儿10M内存,其实在底层屋里内存并没有给你分配1个Byte,只有当你对内存写操作的时候才会给你分配内存)。`

## 学习方法:
学习内存管理,首先需要对内存管理有宏观的认识。不要开始就过于陷入细节,这样很容易让你对内存学习感到绝望。理解知识，需要陷入到Linux本身,从硬件、底层内存分配算法、内核内存分配算法、用户应用程序和内核交互、内存和磁盘缓存、内存和磁盘替换等。当对这些内容理解之后,对整体脉络、主干理解,等具备了这些能力之后,再进行学习具体的数据结构、算法。

## 内存寻址过程:
* CPU开启MMU之后,CPU访问的就是虚拟地址,如果需要访问物理地址需要通过MMU地址映射进行访问(只有MMU可以看到物理地址).

* 例子:
    假设访问虚拟地址0x12345670,Page table页内虚拟地址0x12345000(页号)对应的物理内存为1M.那么0x12345670对应的物理地址为1M＋0x670(页偏移).

* cpu 首先查看TLB看是否有虚拟地址0x12345000和物理地址的映射关系,如果Hit,则MMU直接访问1M+0x670物理内存地址;如果TLB Miss,则查看Page table,MMU再去访问1M+0x670物理内存,同时将内存映射关系缓存在TLB一份。

* 备注:
    1. Page table位于内存中,TLB位于在cpu内部(硬件级页表缓存部件)。
    2. 每个进程都有单独的page table,当进程发生切换时通过更改寄存器值,进程虚拟地址和新的page table关联。
    3. 虚拟地址是一个指针,物理地址是一个整数。


### 虚拟存储器保护工具
    现在计算机系统必须为操作系统提供手段来控制对存储器系统的访问。不应该允许一个用户进程修改它的只读文本段,而且也不应该允许它读或者修改任何内核中的代码和数据结构。不应该允许它读或者写其它进程的私有存储器,并且不允许它修改任何与其它进程共享的虚拟页面,除非所有的共享者都显示地允许它这么做.

    每次CPU生成一个地址时,地址翻译硬件都会读一个PTE(也表条目),所以通过在PTE上添加一些额外的许可位来控制对一个虚拟页面内容的访问.每个PTE增加了三个许可位。SUP位表示进程是否必须运行在内核(超级用户)模式下才能访问该页。运行在内核模式中的进程可以访问任何页面,但是运行在用户模式中的进程只允许访问那些SUP 为0的页面READ位、WRITE位控制对页面的读和写访问.如果一条指令违反了这些许可条件,那么CPU就触发一个一般保护故障,将控制传递给一个内核中的异常处理程序.Unix外壳一般将这种异常报告为"段/页错误"(segmentation/page fault)。

* PTE(页表项)除了RWX权限之外,还有一个访问权限:
    1. 当前页表项,内核态可以访问。
    2. 当前页表项,用户态可以访问。
    3. 当前页表项,只能在内核态访问。

`MMU硬件比较牛逼的地方就是,可以指定PTE仅可以被内核态进行访问。这样所有的用户态进程都无法读取到内核态内容。前一段Intel 出现的Meltdown漏洞,就是用户态进程可以读取到内核态内容。`

`
a[256];                     // 每个成员4096,每个成员4096,保证每个成员间尽可能隔的远些。保证不会被读进cache.
c = *k->内存管理会拦截k     // k是内核地址,假设内存是c
a[c]                        // 这里导致cache命中

for(...)
    a[i]                    // a[0] ~ a[255] 哪个读地最快,就证明k地址存的是哪个:

* 备注:
    1. 有CPU没有MMU硬件,但会有MPU硬件.它主要用做内存保护,不能做虚实映射.更详细的MPU这里不再深入阐述,感兴趣同学可以进行Wikipad.
    2. page fault:
        > 虚拟地址没有对应的物理地址
        > 虚拟地址有对应的物理地址,如果进程向.text写操作,由于代码段只有(RX)权限。此时也会出现"page fault"错误,并且该进程会异常退出。


## DMA

###DMA引擎(DMA Engine)
    DMA引擎就是DMA控制器,从软件上说,从软件上来说，其实就是一个dma框架，在该框架下针对你的具体dma控制器开发出dma驱动,然后其他drivers比如audio,network,crypto等就都可以调用统一的dma相关的api来使用你的dma。
    DMA引擎和CPU都可以访问物理内存任何一个地址.当DMA和CPU同时访问内存时,硬件上有一个仲裁器会判断谁的优先级高,谁就可以访问内存.DMA并不是可以访问所有内存,而是有限制的,只可以访问指定zone内内存。

#### GFP_DMA:
    外设驱动在申请内存时,可以带入GFP_DMA标记。当系统有ZONE_DMA,则从DMA区域分配内存.没有该标记则从ZONE_NORMAL分配.因此想利用ZONE_DMA需要排除其它驱动不再使用此标记.

#### ZONE_HIGHMEM:
    高端内存HIGH_MEM地址空间范围为0xF8000000 ~ 0xFFFFFFFF(896MB~1024MB).那么内核如何借助128MB高端内存空间地址(虚拟地址空间)是如何实现访问所有物理内存?
    当内核想访问高于896MB物理地址内存时,从0xF8000000~0xFFFFFFFF地址空间范围内找一段相应大小空闲的逻辑地址空间,借用一会儿。借用这段逻辑地址空间,建立映射到想访问那段物理内存(即填充内核PTE页面表),临时用一会儿,用完后归还.这样别人也可以借用这段地址空间访问其它物理内存，实现了使用有限的地址空间,访问所有物理内存.

#### NorMal_zone:
    这个区包含的都是能正常映射的页。


## BUDDY算法
    所有zone内存管理统一的算法 - buddy算法.

    buddy 会存在产生大量的0和1页的内存。这样有很多不连续的物理内存,对于通过CPU MMU使用内存方式没有太多问题。因为只要虚拟地址是连续的可以,物理内存是否连续无所谓(性能忽略不计);但对于DMA这种直接访问内存方式会存在问题.

### Buddy算法缺点:
    Buddy算法会导致内存碎片化(空闲内存很多,但连续内存很少)

### CMA(Contiguous Memory Allocator) 连续内存分配器:
    在内存条中找一条内存,当DMA需要使用的时候,让外设使用。如果外设不使用时候,将该内存分配给其它进程实用。CMA不是独立存在,而是和DMA API联合实用。当通过DMA API申请内存时可以使用CMA。DMA底层可以是CMA,也可以是IOMMU等
